{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repro Demo\n",
    "https://github.com/danieldeutsch/repro\n",
    "\n",
    "This notebook demonstrates how to use the Repro library and showcases how it makes running code released by researchers as easy as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does Repro do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running code released with research papers can be hard.\n",
    "Model code often requires specific versions of programming languages and software packages to be installed.\n",
    "It is up to the user to manage these environments and ensure the environment is configured correctly.\n",
    "Dependencies, like pre-trained models, need to be downloaded and placed in the right location in order for the code to run.\n",
    "Over time, these resources are deleted from their original locations and are no longer accessible.\n",
    "\n",
    "Repro is a lightweight Python-based library for addressing these problems by making it as easy as possible to run code released by authors.\n",
    "Each paper supported by Repro has a corresponding Docker image which packages together all of the required runtime libraries and dependencies so the user does not need to manage them.\n",
    "Then, the library provides easy-to-use Python APIs for running the original code within Docker containers.\n",
    "Once you install Repro on a machine with Docker, you can run the code for any of the 30+ papers currently supported by the library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Requirements\n",
    "Running Repro requires Docker to be installed.\n",
    "The normal Docker installation requires you to have root access on the development machine, but there is also a rootless version.\n",
    "We have instructions for how to install Docker as well as some useful commands [here](https://github.com/danieldeutsch/repro/blob/master/tutorials/docker.md).\n",
    "\n",
    "The rest of this demo will assume you are working with a new Python 3.6 environment on a machine with Docker installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing\n",
    "Installing the library is easy!\n",
    "It can be done via `pip`.\n",
    "\n",
    "Here, we install `repro==0.1.3`, which is the latest version of the library tested in this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting repro==0.1.3\n",
      "  Downloading repro-0.1.3-py3-none-any.whl (639 kB)\n",
      "\u001b[K     |████████████████████████████████| 639 kB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting overrides==3.1.0\n",
      "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
      "Collecting parameterized==0.8.1\n",
      "  Downloading parameterized-0.8.1-py2.py3-none-any.whl (26 kB)\n",
      "Collecting pytest==6.2.4\n",
      "  Downloading pytest-6.2.4-py3-none-any.whl (280 kB)\n",
      "\u001b[K     |████████████████████████████████| 280 kB 136.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting datasets==1.9.0\n",
      "  Downloading datasets-1.9.0-py3-none-any.whl (262 kB)\n",
      "\u001b[K     |████████████████████████████████| 262 kB 124.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting black==21.7b0\n",
      "  Downloading black-21.7b0-py3-none-any.whl (141 kB)\n",
      "\u001b[K     |████████████████████████████████| 141 kB 47.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docker==5.0.0\n",
      "  Downloading docker-5.0.0-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 130.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six==1.16.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting tomli<2.0.0,>=0.2.6\n",
      "  Downloading tomli-1.2.3-py3-none-any.whl (12 kB)\n",
      "Collecting appdirs\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting regex>=2020.1.8\n",
      "  Downloading regex-2022.1.18-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
      "\u001b[K     |████████████████████████████████| 748 kB 109.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pathspec<1,>=0.8.1\n",
      "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting dataclasses>=0.6\n",
      "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Collecting typing-extensions>=3.7.4\n",
      "  Downloading typing_extensions-4.0.1-py3-none-any.whl (22 kB)\n",
      "Collecting typed-ast>=1.4.2\n",
      "  Downloading typed_ast-1.5.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (831 kB)\n",
      "\u001b[K     |████████████████████████████████| 831 kB 15.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mypy-extensions>=0.4.3\n",
      "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
      "Collecting click>=7.1.2\n",
      "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 4.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.17\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8 MB 20.7 MB/s eta 0:00:01     |████████████████████████████    | 13.0 MB 20.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2-py36-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 122.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub<0.1.0\n",
      "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 1.6 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow!=4.0.0,>=1.0.0\n",
      "  Downloading pyarrow-6.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.6 MB 128.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 3.4 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 143.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests>=2.19.0\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 773 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /mnt/cogcomp-archive/shared/ddeutsch/envs/repro-demo/lib/python3.6/site-packages (from datasets==1.9.0->repro==0.1.3) (21.3)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 2.4 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec>=2021.05.0\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 147.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp36-cp36m-manylinux2010_x86_64.whl (243 kB)\n",
      "\u001b[K     |████████████████████████████████| 243 kB 146.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: websocket-client>=0.32.0 in /mnt/castor/seas_home/d/ddeutsch/.local/lib/python3.6/site-packages (from docker==5.0.0->repro==0.1.3) (0.56.0)\n",
      "Collecting attrs>=19.2.0\n",
      "  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 6.7 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting pluggy<1.0.0a1,>=0.12\n",
      "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 4.6 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\n",
      "\u001b[K     |████████████████████████████████| 603 kB 143.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /mnt/cogcomp-archive/shared/ddeutsch/envs/repro-demo/lib/python3.6/site-packages (from packaging->datasets==1.9.0->repro==0.1.3) (3.0.4)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 6.6 MB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /mnt/cogcomp-archive/shared/ddeutsch/envs/repro-demo/lib/python3.6/site-packages (from requests>=2.19.0->datasets==1.9.0->repro==0.1.3) (2020.6.20)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.10-py3-none-any.whl (39 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 147.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /mnt/cogcomp-archive/shared/ddeutsch/envs/repro-demo/lib/python3.6/site-packages (from pandas->datasets==1.9.0->repro==0.1.3) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /mnt/castor/seas_home/d/ddeutsch/.local/lib/python3.6/site-packages (from pandas->datasets==1.9.0->repro==0.1.3) (2017.3)\n",
      "Building wheels for collected packages: overrides\n",
      "  Building wheel for overrides (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=92857d301af825bc226319af6ffce56e7f9c6865131a9c343108dd41904cda88\n",
      "  Stored in directory: /mnt/castor/seas_home/d/ddeutsch/.cache/pip/wheels/e6/3b/34/ae59fc8d35c37f01099425ab73599e45e9b9b599a7ccc2c45f\n",
      "Successfully built overrides\n",
      "Installing collected packages: zipp, urllib3, typing-extensions, six, idna, charset-normalizer, tqdm, requests, pyyaml, numpy, importlib-metadata, filelock, dill, xxhash, typed-ast, tomli, toml, regex, pyarrow, py, pluggy, pathspec, pandas, mypy-extensions, multiprocess, iniconfig, huggingface-hub, fsspec, dataclasses, click, attrs, appdirs, pytest, parameterized, overrides, docker, datasets, black, repro\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tfds-nightly 0.0.1.dev201812110014 requires protobuf, which is not installed.\n",
      "tfds-nightly 0.0.1.dev201812110014 requires termcolor, which is not installed.\n",
      "tfds-nightly 0.0.1.dev201812110014 requires wrapt, which is not installed.\n",
      "tensor2tensor 1.11.0 requires bz2file, which is not installed.\n",
      "tensor2tensor 1.11.0 requires google-api-python-client, which is not installed.\n",
      "tensor2tensor 1.11.0 requires h5py, which is not installed.\n",
      "tensor2tensor 1.11.0 requires scipy, which is not installed.\n",
      "sphinx 1.5.3 requires alabaster<0.8,>=0.7, which is not installed.\n",
      "sphinx 1.5.3 requires babel!=2.0,>=1.3, which is not installed.\n",
      "sphinx 1.5.3 requires docutils>=0.11, which is not installed.\n",
      "sphinx 1.5.3 requires imagesize, which is not installed.\n",
      "sphinx 1.5.3 requires snowballstemmer>=1.1, which is not installed.\n",
      "sphinx-autobuild 0.7.1 requires watchdog>=0.7.1, which is not installed.\n",
      "oauth2client 4.1.3 requires httplib2>=0.9.1, which is not installed.\n",
      "oauth2client 4.1.3 requires pyasn1>=0.1.7, which is not installed.\n",
      "oauth2client 4.1.3 requires rsa>=3.1.4, which is not installed.\n",
      "moto 1.3.4 requires boto3>=1.6.16, which is not installed.\n",
      "moto 1.3.4 requires botocore>=1.9.16, which is not installed.\n",
      "moto 1.3.4 requires cryptography>=2.0.0, which is not installed.\n",
      "moto 1.3.4 requires pyaml, which is not installed.\n",
      "moto 1.3.4 requires responses>=0.9.0, which is not installed.\n",
      "moto 1.3.4 requires werkzeug, which is not installed.\n",
      "gym 0.10.9 requires scipy, which is not installed.\n",
      "flask 1.0.2 requires itsdangerous>=0.24, which is not installed.\n",
      "flask 1.0.2 requires Werkzeug>=0.14, which is not installed.\n",
      "aws-xray-sdk 0.95 requires jsonpickle, which is not installed.\n",
      "aws-xray-sdk 0.95 requires wrapt, which is not installed.\n",
      "astroid 1.6.6 requires wrapt, which is not installed.\n",
      "aiohttp 3.6.0 requires chardet<4.0,>=2.0, which is not installed.\u001b[0m\n",
      "Successfully installed appdirs-1.4.4 attrs-21.4.0 black-21.7b0 charset-normalizer-2.0.10 click-8.0.3 dataclasses-0.8 datasets-1.9.0 dill-0.3.4 docker-5.0.0 filelock-3.4.1 fsspec-2022.1.0 huggingface-hub-0.0.19 idna-3.3 importlib-metadata-4.8.3 iniconfig-1.1.1 multiprocess-0.70.12.2 mypy-extensions-0.4.3 numpy-1.19.5 overrides-3.1.0 pandas-1.1.5 parameterized-0.8.1 pathspec-0.9.0 pluggy-0.13.1 py-1.11.0 pyarrow-6.0.1 pytest-6.2.4 pyyaml-6.0 regex-2022.1.18 repro-0.1.3 requests-2.27.1 six-1.16.0 toml-0.10.2 tomli-1.2.3 tqdm-4.62.3 typed-ast-1.5.1 typing-extensions-4.0.1 urllib3-1.26.8 xxhash-2.0.2 zipp-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install repro==0.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library itself is very lightweight. It has a very minimal set of dependencies which are easy to install.\n",
    "\n",
    "After the installation is complete, you can run any of the 30+ models which are included in the library with virtually no extra work.\n",
    "See [here](https://github.com/danieldeutsch/repro/blob/master/Papers.md) for a list of publications that have a Dockerized implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous Setup\n",
    "Here, we setup some logging so that useful information will be shown in the output of the notebook cells.\n",
    "This step is not required to run the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Library\n",
    "This notebook demonstrates how Repro makes running code released with research papers much easier.\n",
    "To do so, we will show how to use three different summarization models to generate summaries of an input document, then evaluate those summaries with three different automatic evaluation metrics.\n",
    "\n",
    "First, we define the input document and the gold reference summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This document/reference pair comes from the CNN/DailyMail dataset. We\n",
    "# don't actually use the full document, but it is ok for the purposes of this demo\n",
    "document = (\n",
    "    \"(CNN) President Barack Obama took part in a roundtable discussion this \"\n",
    "    \"week on climate change, refocusing on the issue from a public health \"\n",
    "    \"vantage point. After the event at Washington's Howard University on Tuesday, \"\n",
    "    \"Obama sat down with me for a one-on-one interview. I asked him about the science \"\n",
    "    \"behind climate change and public health and the message he wants the average \"\n",
    "    \"American to take away, as well as how enforceable his action plan is. Here are \"\n",
    "    \"five things I learned: . The President enrolled at Occidental College in Los Angeles \"\n",
    "    \"in 1979 (he transferred to Columbia University his junior year). While in L.A., \"\n",
    "    \"he said, the air was so bad that it prevented him from running outside. He remembers \"\n",
    "    \"the air quality alerts and how people with respiratory problems had to stay inside. \"\n",
    "    \"He credits the Clean Air Act with making Americans \\\"a lot\\\" healthier, in addition \"\n",
    "    \"to being able to \\\"see the mountains in the background because they aren't covered in smog.\\\" \"\n",
    "    \"Obama also said the instances of asthma and other respiratory diseases went down after \"\n",
    "    \"these measures were taken. Peer-reviewed Environmental Protection Agency studies say \"\n",
    "    \"that the Clean Air Act and subsequent amendments have reduced early deaths associated with \"\n",
    "    \"exposure to ambient fine particle pollution and ozone, and reduced illnesses such as chronic \"\n",
    "    \"bronchitis and acute myocardial infarction. The EPA estimates that, between 1970 and 2010, \"\n",
    "    \"the act and its amendments prevented 365,000 early deaths from particulate matter alone. \"\n",
    "    \"\\\"No challenge poses more of a public threat than climate change,\\\" the President told me.\"\n",
    ")\n",
    "\n",
    "reference = (\n",
    "    \"\\\"No challenge poses more of a public threat than climate change,\\\" the President says. \"\n",
    "    \"He credits the Clean Air Act with making Americans \\\"a lot\\\" healthier.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use three different summarization models to generate summaries of the input document.\n",
    "\n",
    "Those models are:\n",
    "- **BertSumExtAbs** from \"Text Summarization with Pretrained Encoders\" ([Liu & Lapata, 2019](https://arxiv.org/abs/1908.08345))\n",
    "- **BART** from \"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension\" ([Lewis et al., 2020](https://arxiv.org/abs/1910.13461))\n",
    "- **GSum** from \"GSum: A General Framework for Guided Neural Abstractive Summarization\" ([Dou et al., 2021](https://arxiv.org/abs/2010.08014))\n",
    "\n",
    "Each model wrapped in its own `Model` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model classes\n",
    "from repro.models.liu2019 import BertSumExtAbs\n",
    "from repro.models.lewis2020 import BART\n",
    "from repro.models.dou2021 import SentenceGSumModel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the models' constructors accepts different parameters like the GPU device, Docker image to use, or pre-trained model to use.\n",
    "The default parameter values work for this demo, but we show examples of what you can configure below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "liu2019 = BertSumExtAbs(device=0)\n",
    "lewis2020 = BART(model=\"bart.large.cnn\")\n",
    "dou2021 = SentenceGSumModel(batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the models has a `predict()` function which takes the source document as input and generates a summary.\n",
    "When the `predict()` function is called, Repro launches each model's Docker container that contains its code, pre-trained models, and pre-configured dependencies, passes the input to the container, runs inference within the container, and returns the result to the current Python process.\n",
    "If the required Docker image is not local to the host machine, it is downloaded automatically from [DockerHub](https://hub.docker.com/u/danieldeutsch).\n",
    "\n",
    "This process is hidden from Repro users, who do not need to know the details of what's going on in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:repro.models.liu2019.models:Predicting summaries for 1 documents with pretrained model bertsumextabs_cnndm.pt, task abs and Docker image danieldeutsch/liu2019:1.0.\n",
      "INFO:repro.common.docker:Image danieldeutsch/liu2019:1.0 does not exist locally. Pulling\n",
      "INFO:repro.common.docker:Finished pulling danieldeutsch/liu2019:1.0\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/liu2019:1.0: \"/bin/sh -c 'python preprocess.py  --input-file /tmp0/documents.txt  --output-file /tmp1/tokenized.txt && cd PreSumm/src && python train.py  -task abs  -mode test_text  -test_from ../../bertsumextabs_cnndm.pt  -text_src /tmp1/tokenized.txt  -result_path /tmp1/out  -visible_gpus 0 -max_length 200 -min_length 50 -alpha 0.95'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding annotator tokenize\n",
      "No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "Adding annotator ssplit\n",
      "\n",
      "Processing file /tmp/tmpbcojditv/input/0 ... writing to /tmp/tmpbcojditv/output/0.json\n",
      "Annotating file /tmp/tmpbcojditv/input/0 ... done [0.1 sec].\n",
      "\n",
      "Annotation pipeline timing information:\n",
      "TokenizerAnnotator: 0.1 sec.\n",
      "WordsToSentencesAnnotator: 0.0 sec.\n",
      "TOTAL: 0.1 sec. for 292 tokens at 5122.8 tokens/sec.\n",
      "Pipeline setup: 0.1 sec.\n",
      "Total time for StanfordCoreNLP pipeline: 0.3 sec.\n",
      "Tokenizing documents with CoreNLP\n",
      "Finished tokenizing documents\n",
      "[2022-01-23 04:14:16,891 INFO] Loading checkpoint from ../../bertsumextabs_cnndm.pt\n",
      "[2022-01-23 04:14:18,599 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "[2022-01-23 04:14:18,599 INFO] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2022-01-23 04:14:18,601 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "[2022-01-23 04:14:25,158 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2022-01-23 04:14:25,233 INFO] loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "Namespace(accum_count=1, alpha=0.95, batch_size=140, beam_size=5, bert_data_path='../bert_data_new/cnndm', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/cnndm.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_ndocs_in_batch=6, max_pos=512, max_tgt_len=140, min_length=50, mode='test_text', model_path='../models/', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='/tmp1/out', save_checkpoint_steps=5, seed=666, sep_optim=False, share_emb=False, task='abs', temp_dir='../temp', test_all=False, test_batch_size=200, test_from='../../bertsumextabs_cnndm.pt', test_start_from=-1, text_src='/tmp1/tokenized.txt', text_tgt='', train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='0', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
      " 50%|█████     | 1/2 [00:00<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.models.lewis2020.model:Predicting summaries for 1 documents with Docker image danieldeutsch/lewis2020:1.1\n",
      "INFO:repro.common.docker:Image danieldeutsch/lewis2020:1.1 does not exist locally. Pulling\n",
      "INFO:repro.common.docker:Finished pulling danieldeutsch/lewis2020:1.1\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/lewis2020:1.1: \"/bin/sh -c 'cd fairseq && CUDA_VISIBLE_DEVICES=0 python examples/bart/summarize.py  --model-dir ../bart.large.cnn  --model-file model.pt  --src /tmp0/documents.txt  --out /tmp1/summaries.txt'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042301B [00:00, 2455215.50B/s]\n",
      "456318B [00:00, 1406379.63B/s]\n",
      "/app/fairseq/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  beams_buf = indices_buf // vocab_size\n",
      "/app/fairseq/fairseq/sequence_generator.py:670: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  unfin_idx = idx // beam_size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.models.dou2021.models:Generating summaries for 1 inputs and image danieldeutsch/dou2021:1.0.\n",
      "INFO:repro.models.dou2021.models:Extracting guidance signal\n",
      "INFO:repro.models.liu2019.models:Predicting summaries for 1 documents with pretrained model bertsumext_cnndm.pt, task ext and Docker image danieldeutsch/liu2019:1.0.\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/liu2019:1.0: \"/bin/sh -c 'python preprocess.py  --input-file /tmp0/documents.txt  --output-file /tmp1/tokenized.txt && cd PreSumm/src && python train.py  -task ext  -mode test_text  -test_from ../../bertsumext_cnndm.pt  -text_src /tmp1/tokenized.txt  -result_path /tmp1/out  -visible_gpus 0'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding annotator tokenize\n",
      "No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "Adding annotator ssplit\n",
      "\n",
      "Processing file /tmp/tmpp_7x7ydw/input/0 ... writing to /tmp/tmpp_7x7ydw/output/0.json\n",
      "Annotating file /tmp/tmpp_7x7ydw/input/0 ... done [0.1 sec].\n",
      "\n",
      "Annotation pipeline timing information:\n",
      "TokenizerAnnotator: 0.1 sec.\n",
      "WordsToSentencesAnnotator: 0.0 sec.\n",
      "TOTAL: 0.1 sec. for 292 tokens at 5407.4 tokens/sec.\n",
      "Pipeline setup: 0.1 sec.\n",
      "Total time for StanfordCoreNLP pipeline: 0.3 sec.\n",
      "Tokenizing documents with CoreNLP\n",
      "Finished tokenizing documents\n",
      "[2022-01-23 04:14:51,117 INFO] Loading checkpoint from ../../bertsumext_cnndm.pt\n",
      "[2022-01-23 04:14:51,898 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "[2022-01-23 04:14:51,898 INFO] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2022-01-23 04:14:51,900 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "[2022-01-23 04:14:56,469 INFO] * number of parameters: 120512513\n",
      "[2022-01-23 04:14:56,475 INFO] loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "Namespace(accum_count=1, alpha=0.6, batch_size=140, beam_size=5, bert_data_path='../bert_data_new/cnndm', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/cnndm.log', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=150, max_ndocs_in_batch=6, max_pos=512, max_tgt_len=140, min_length=15, mode='test_text', model_path='../models/', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='/tmp1/out', save_checkpoint_steps=5, seed=666, sep_optim=False, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=200, test_from='../../bertsumext_cnndm.pt', test_start_from=-1, text_src='/tmp1/tokenized.txt', text_tgt='', train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='0', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
      "gpu_rank 0\n",
      " 50%|█████     | 1/2 [00:00<00:00, 42.58it/s]\n",
      "[2022-01-23 04:14:56,526 INFO] Validation xent: 0 at step -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.common.docker:Image danieldeutsch/dou2021:1.0 does not exist locally. Pulling\n",
      "INFO:repro.common.docker:Finished pulling danieldeutsch/dou2021:1.0\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/dou2021:1.0: \"/bin/sh -c 'cd guided_summarization/bart && CUDA_VISIBLE_DEVICES=0 python summarize.py  /tmp0/documents.txt  /tmp0/guidance.txt  /tmp1/summaries.txt  ../bart_sentence  model.pt  ../bart_sentence  4'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042301B [00:01, 630477.60B/s]\n",
      "456318B [00:00, 1381149.65B/s]\n",
      "Running prediction: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:repro.common.docker:Command finished\n"
     ]
    }
   ],
   "source": [
    "summary1 = liu2019.predict(document)\n",
    "summary2 = lewis2020.predict(document)\n",
    "summary3 = dou2021.predict(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President Barack Obama took part in a roundtable discussion this week on climate change. Obama sat down with CNN's John Sutter for a one-on-one interview. Sutter asked him about the science behind climate change and public health. Obama: \"No challenge poses more of a public threat\"\n"
     ]
    }
   ],
   "source": [
    "print(summary2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will show how each of the 3 output summaries can be evaluated with three different reference-based automatic evaluation metrics.\n",
    "The metrics are:\n",
    "- **ROUGE** from \"ROUGE: A Package for Automatic Evaluation of Summaries\" ([Lin, 2004](https://aclanthology.org/W04-1013/))\n",
    "- **BLEURT** from \"BLEURT: Learning Robust Metrics for Text Generation\" ([Sellam et al., 2020](https://arxiv.org/abs/2004.04696))\n",
    "- **QAEval** from \"Towards Question-Answering as an Automatic Metric for Evaluating the Content Quality of a Summary\" ([Deutsch et al., 2021](https://arxiv.org/abs/2010.00490))\n",
    "\n",
    "Even though these are metrics and not necessarily \"models,\" each is still implemented by a `Model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repro.models.lin2004 import ROUGE\n",
    "from repro.models.sellam2020 import BLEURT\n",
    "from repro.models.deutsch2021 import QAEval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the summarization models, each of the metrics can be instantiated with its own parameters.\n",
    "The defaults are OK for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = ROUGE()\n",
    "bleurt = BLEURT()\n",
    "qaeval = QAEval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate each of the generated summiares using the three metrics.\n",
    "Again, the `predict()` method launches Docker containers for each of the three metrics and scores the generated summaries with the papers' original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:repro.models.lin2004.model:Calculating ROUGE for 1 inputs\n",
      "INFO:repro.common.docker:Image danieldeutsch/lin2004:1.0 does not exist locally. Pulling\n",
      "INFO:repro.common.docker:Finished pulling danieldeutsch/lin2004:1.0\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/lin2004:1.0: \"/bin/sh -c 'python sentence_split.py /tmp0/input.txt /tmp1/output.txt'\"\n",
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/lin2004:1.0: \"/bin/sh -c 'perl ROUGE-1.5.5/ROUGE-1.5.5.pl  -e ROUGE-1.5.5/data  -n 4  -a  -c 95  -r 1000  -p 0.5  -t 0  -d -m -2 4 -u /tmp0/config.xml'\"\n",
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.models.sellam2020.model:Calculating BLEURT with model bleurt-base-128 and image danieldeutsch/sellam2020:1.0 on 1 inputs.\n",
      "INFO:repro.common.docker:Image danieldeutsch/sellam2020:1.0 does not exist locally. Pulling\n",
      "INFO:repro.common.docker:Finished pulling danieldeutsch/sellam2020:1.0\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/sellam2020:1.0: \"/bin/sh -c 'export CUDA_VISIBLE_DEVICES=0 && cd bleurt && python -m bleurt.score_files  -sentence_pairs_file /tmp0/input.jsonl  -bleurt_checkpoint ../bleurt-base-128  -scores_file /tmp0/output.jsonl  -bleurt_batch_size 16'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint ../bleurt-base-128.\n",
      "I0123 04:15:23.872298 140301559633728 score.py:161] Reading checkpoint ../bleurt-base-128.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "I0123 04:15:23.872550 140301559633728 checkpoint.py:92] Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "I0123 04:15:23.872735 140301559633728 checkpoint.py:96] Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "I0123 04:15:23.872796 140301559633728 checkpoint.py:98] Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "I0123 04:15:23.872840 140301559633728 checkpoint.py:102] ... name:bert_custom\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "I0123 04:15:23.872882 140301559633728 checkpoint.py:102] ... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "I0123 04:15:23.872944 140301559633728 checkpoint.py:102] ... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "I0123 04:15:23.873003 140301559633728 checkpoint.py:102] ... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:128\n",
      "I0123 04:15:23.873045 140301559633728 checkpoint.py:102] ... max_seq_length:128\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "I0123 04:15:23.873089 140301559633728 score.py:168] Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "I0123 04:15:23.873130 140301559633728 tokenizers.py:40] Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "I0123 04:15:23.951372 140301559633728 tokenizers.py:45] WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "I0123 04:15:23.951483 140301559633728 score.py:57] Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "I0123 04:15:23.951530 140301559633728 score.py:62] Loading model.\n",
      "2022-01-23 04:15:24.372596: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-23 04:15:24.454648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-01-23 04:15:24.454954: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-23 04:15:24.461793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-23 04:15:24.465898: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-23 04:15:24.466845: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-23 04:15:24.474040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-23 04:15:24.475554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-23 04:15:24.490315: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-23 04:15:24.492314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-01-23 04:15:24.492570: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2022-01-23 04:15:24.507538: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n",
      "2022-01-23 04:15:24.513778: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9768000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-23 04:15:24.513797: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-23 04:15:24.597601: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x644e650 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-23 04:15:24.597640: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2022-01-23 04:15:24.599272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-01-23 04:15:24.599317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-23 04:15:24.599326: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-23 04:15:24.599335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-23 04:15:24.599343: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-23 04:15:24.599352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-23 04:15:24.599363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-23 04:15:24.599371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-23 04:15:24.601442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-01-23 04:15:24.601787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-23 04:15:24.603325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-23 04:15:24.603336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2022-01-23 04:15:24.603340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2022-01-23 04:15:24.605575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10210 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W0123 04:15:25.338723 140301559633728 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "I0123 04:15:26.957016 140301559633728 score.py:174] BLEURT initialized.\n",
      "INFO:tensorflow:Computing BLEURT scores...\n",
      "I0123 04:15:26.957181 140301559633728 score_files.py:133] Computing BLEURT scores...\n",
      "2022-01-23 04:15:27.258853: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "INFO:tensorflow:BLEURT scores computed.\n",
      "I0123 04:15:27.513254 140301559633728 score_files.py:141] BLEURT scores computed.\n",
      "INFO:tensorflow:Writing to disk.\n",
      "I0123 04:15:27.513468 140301559633728 score_files.py:144] Writing to disk.\n",
      "INFO:tensorflow:Done.\n",
      "I0123 04:15:27.513678 140301559633728 score_files.py:151] Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.models.deutsch2021.models:Calculating QAEval for 1 inputs\n",
      "INFO:repro.common.docker:Image danieldeutsch/deutsch2021:1.0 does not exist locally. Pulling\n",
      "INFO:repro.common.docker:Finished pulling danieldeutsch/deutsch2021:1.0\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/deutsch2021:1.0: \"/bin/sh -c 'export CUDA_VISIBLE_DEVICES=0 && python score.py  --input-file /tmp0/input.jsonl  --kwargs '\\''{\"cuda_device\": 0, \"generation_batch_size\": 8, \"answering_batch_size\": 8, \"use_lerc\": true, \"lerc_batch_size\": 8}'\\''  --output-file /tmp0/output.jsonl'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['final_logits_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.models.lin2004.model:Calculating ROUGE for 1 inputs\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/lin2004:1.0: \"/bin/sh -c 'python sentence_split.py /tmp0/input.txt /tmp1/output.txt'\"\n",
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/lin2004:1.0: \"/bin/sh -c 'python sentence_split.py /tmp0/input.txt /tmp1/output.txt'\"\n",
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/lin2004:1.0: \"/bin/sh -c 'perl ROUGE-1.5.5/ROUGE-1.5.5.pl  -e ROUGE-1.5.5/data  -n 4  -a  -c 95  -r 1000  -p 0.5  -t 0  -d -m -2 4 -u /tmp0/config.xml'\"\n",
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.models.sellam2020.model:Calculating BLEURT with model bleurt-base-128 and image danieldeutsch/sellam2020:1.0 on 1 inputs.\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/sellam2020:1.0: \"/bin/sh -c 'export CUDA_VISIBLE_DEVICES=0 && cd bleurt && python -m bleurt.score_files  -sentence_pairs_file /tmp0/input.jsonl  -bleurt_checkpoint ../bleurt-base-128  -scores_file /tmp0/output.jsonl  -bleurt_batch_size 16'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint ../bleurt-base-128.\n",
      "I0123 04:16:23.210313 140488187754304 score.py:161] Reading checkpoint ../bleurt-base-128.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "I0123 04:16:23.210583 140488187754304 checkpoint.py:92] Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "I0123 04:16:23.210783 140488187754304 checkpoint.py:96] Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "I0123 04:16:23.210850 140488187754304 checkpoint.py:98] Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "I0123 04:16:23.210918 140488187754304 checkpoint.py:102] ... name:bert_custom\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "I0123 04:16:23.210967 140488187754304 checkpoint.py:102] ... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "I0123 04:16:23.211043 140488187754304 checkpoint.py:102] ... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "I0123 04:16:23.211117 140488187754304 checkpoint.py:102] ... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:128\n",
      "I0123 04:16:23.211166 140488187754304 checkpoint.py:102] ... max_seq_length:128\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "I0123 04:16:23.211217 140488187754304 score.py:168] Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "I0123 04:16:23.211265 140488187754304 tokenizers.py:40] Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "I0123 04:16:23.295461 140488187754304 tokenizers.py:45] WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "I0123 04:16:23.295561 140488187754304 score.py:57] Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "I0123 04:16:23.295622 140488187754304 score.py:62] Loading model.\n",
      "2022-01-23 04:16:23.716402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-23 04:16:23.800552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-01-23 04:16:23.800922: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-23 04:16:23.807787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-23 04:16:23.811856: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-23 04:16:23.812858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-23 04:16:23.820066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-23 04:16:23.821681: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-23 04:16:23.836119: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-23 04:16:23.838329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-01-23 04:16:23.838630: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2022-01-23 04:16:23.853816: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n",
      "2022-01-23 04:16:23.859721: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc2dc000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-23 04:16:23.859738: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-23 04:16:23.943689: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x62baa80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-23 04:16:23.943716: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2022-01-23 04:16:23.945323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-01-23 04:16:23.945369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-23 04:16:23.945378: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-23 04:16:23.945385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-23 04:16:23.945392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-23 04:16:23.945399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-23 04:16:23.945405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-23 04:16:23.945413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-23 04:16:23.947371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-01-23 04:16:23.947670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-23 04:16:23.949193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-23 04:16:23.949203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2022-01-23 04:16:23.949208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2022-01-23 04:16:23.951349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10210 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W0123 04:16:24.681359 140488187754304 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "I0123 04:16:26.300019 140488187754304 score.py:174] BLEURT initialized.\n",
      "INFO:tensorflow:Computing BLEURT scores...\n",
      "I0123 04:16:26.300197 140488187754304 score_files.py:133] Computing BLEURT scores...\n",
      "2022-01-23 04:16:26.607891: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "INFO:tensorflow:BLEURT scores computed.\n",
      "I0123 04:16:26.860045 140488187754304 score_files.py:141] BLEURT scores computed.\n",
      "INFO:tensorflow:Writing to disk.\n",
      "I0123 04:16:26.860224 140488187754304 score_files.py:144] Writing to disk.\n",
      "INFO:tensorflow:Done.\n",
      "I0123 04:16:26.860441 140488187754304 score_files.py:151] Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.models.deutsch2021.models:Calculating QAEval for 1 inputs\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/deutsch2021:1.0: \"/bin/sh -c 'export CUDA_VISIBLE_DEVICES=0 && python score.py  --input-file /tmp0/input.jsonl  --kwargs '\\''{\"cuda_device\": 0, \"generation_batch_size\": 8, \"answering_batch_size\": 8, \"use_lerc\": true, \"lerc_batch_size\": 8}'\\''  --output-file /tmp0/output.jsonl'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['final_logits_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.models.lin2004.model:Calculating ROUGE for 1 inputs\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/lin2004:1.0: \"/bin/sh -c 'python sentence_split.py /tmp0/input.txt /tmp1/output.txt'\"\n",
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/lin2004:1.0: \"/bin/sh -c 'python sentence_split.py /tmp0/input.txt /tmp1/output.txt'\"\n",
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/lin2004:1.0: \"/bin/sh -c 'perl ROUGE-1.5.5/ROUGE-1.5.5.pl  -e ROUGE-1.5.5/data  -n 4  -a  -c 95  -r 1000  -p 0.5  -t 0  -d -m -2 4 -u /tmp0/config.xml'\"\n",
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.models.sellam2020.model:Calculating BLEURT with model bleurt-base-128 and image danieldeutsch/sellam2020:1.0 on 1 inputs.\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/sellam2020:1.0: \"/bin/sh -c 'export CUDA_VISIBLE_DEVICES=0 && cd bleurt && python -m bleurt.score_files  -sentence_pairs_file /tmp0/input.jsonl  -bleurt_checkpoint ../bleurt-base-128  -scores_file /tmp0/output.jsonl  -bleurt_batch_size 16'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint ../bleurt-base-128.\n",
      "I0123 04:17:19.973246 140441338484544 score.py:161] Reading checkpoint ../bleurt-base-128.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "I0123 04:17:19.973578 140441338484544 checkpoint.py:92] Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "I0123 04:17:19.973781 140441338484544 checkpoint.py:96] Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "I0123 04:17:19.973840 140441338484544 checkpoint.py:98] Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "I0123 04:17:19.973885 140441338484544 checkpoint.py:102] ... name:bert_custom\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "I0123 04:17:19.973930 140441338484544 checkpoint.py:102] ... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "I0123 04:17:19.974001 140441338484544 checkpoint.py:102] ... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "I0123 04:17:19.974066 140441338484544 checkpoint.py:102] ... do_lower_case:True\n",
      "INFO:tensorflow:... max_seq_length:128\n",
      "I0123 04:17:19.974110 140441338484544 checkpoint.py:102] ... max_seq_length:128\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "I0123 04:17:19.974160 140441338484544 score.py:168] Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "I0123 04:17:19.974211 140441338484544 tokenizers.py:40] Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "I0123 04:17:20.053773 140441338484544 tokenizers.py:45] WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "I0123 04:17:20.053886 140441338484544 score.py:57] Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "I0123 04:17:20.053936 140441338484544 score.py:62] Loading model.\n",
      "2022-01-23 04:17:20.474737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-23 04:17:20.555521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-01-23 04:17:20.555807: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-23 04:17:20.562862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-23 04:17:20.566968: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-23 04:17:20.567994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-23 04:17:20.575452: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-23 04:17:20.576973: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-23 04:17:20.592152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-23 04:17:20.594368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-01-23 04:17:20.594665: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2022-01-23 04:17:20.609431: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n",
      "2022-01-23 04:17:20.615434: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb7f4000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-23 04:17:20.615452: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-23 04:17:20.699467: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5da8200 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-23 04:17:20.699495: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2022-01-23 04:17:20.701475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-01-23 04:17:20.701540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-23 04:17:20.701555: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-23 04:17:20.701563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-23 04:17:20.701570: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-23 04:17:20.701578: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-23 04:17:20.701585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-23 04:17:20.701592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-23 04:17:20.703929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-01-23 04:17:20.704221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-23 04:17:20.705698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-23 04:17:20.705713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2022-01-23 04:17:20.705717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2022-01-23 04:17:20.707840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10210 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W0123 04:17:21.447612 140441338484544 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "I0123 04:17:23.081361 140441338484544 score.py:174] BLEURT initialized.\n",
      "INFO:tensorflow:Computing BLEURT scores...\n",
      "I0123 04:17:23.081542 140441338484544 score_files.py:133] Computing BLEURT scores...\n",
      "2022-01-23 04:17:23.384523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "INFO:tensorflow:BLEURT scores computed.\n",
      "I0123 04:17:23.640683 140441338484544 score_files.py:141] BLEURT scores computed.\n",
      "INFO:tensorflow:Writing to disk.\n",
      "I0123 04:17:23.640866 140441338484544 score_files.py:144] Writing to disk.\n",
      "INFO:tensorflow:Done.\n",
      "I0123 04:17:23.641067 140441338484544 score_files.py:151] Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:repro.common.docker:Command finished\n",
      "INFO:repro.models.deutsch2021.models:Calculating QAEval for 1 inputs\n",
      "INFO:repro.common.docker:Running command in Docker image danieldeutsch/deutsch2021:1.0: \"/bin/sh -c 'export CUDA_VISIBLE_DEVICES=0 && python score.py  --input-file /tmp0/input.jsonl  --kwargs '\\''{\"cuda_device\": 0, \"generation_batch_size\": 8, \"answering_batch_size\": 8, \"use_lerc\": true, \"lerc_batch_size\": 8}'\\''  --output-file /tmp0/output.jsonl'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['final_logits_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:repro.common.docker:Command finished\n"
     ]
    }
   ],
   "source": [
    "names = [\"bertsumextabs\", \"bart\", \"gsum\"]\n",
    "summaries = [summary1, summary2, summary3]\n",
    "\n",
    "results = {}\n",
    "for name, summary in zip(names, summaries):\n",
    "    results[name] = {\n",
    "        \"rouge\": rouge.predict(summary, [reference]),\n",
    "        \"bleurt\": bleurt.predict(summary, [reference]),\n",
    "        \"qaeval\": qaeval.predict(summary, [reference]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"bertsumextabs\": {\n",
      "    \"rouge\": {\n",
      "      \"rouge-1\": {\n",
      "        \"recall\": 65.385,\n",
      "        \"precision\": 40.476,\n",
      "        \"f1\": 50.0\n",
      "      },\n",
      "      \"rouge-2\": {\n",
      "        \"recall\": 48.0,\n",
      "        \"precision\": 29.268,\n",
      "        \"f1\": 36.363\n",
      "      },\n",
      "      \"rouge-3\": {\n",
      "        \"recall\": 41.667,\n",
      "        \"precision\": 25.0,\n",
      "        \"f1\": 31.25\n",
      "      },\n",
      "      \"rouge-4\": {\n",
      "        \"recall\": 39.129999999999995,\n",
      "        \"precision\": 23.077,\n",
      "        \"f1\": 29.032000000000004\n",
      "      },\n",
      "      \"rouge-l\": {\n",
      "        \"recall\": 57.692,\n",
      "        \"precision\": 35.714,\n",
      "        \"f1\": 44.117\n",
      "      },\n",
      "      \"rouge-su4\": {\n",
      "        \"recall\": 47.857,\n",
      "        \"precision\": 28.389999999999997,\n",
      "        \"f1\": 35.638\n",
      "      }\n",
      "    },\n",
      "    \"bleurt\": {\n",
      "      \"bleurt\": {\n",
      "        \"mean\": -0.6845605969429016,\n",
      "        \"max\": -0.6845605969429016\n",
      "      }\n",
      "    },\n",
      "    \"qaeval\": {\n",
      "      \"qa-eval\": {\n",
      "        \"lerc\": 1.8411507776805334,\n",
      "        \"em\": 0.2857142857142857,\n",
      "        \"is_answered\": 0.5714285714285714,\n",
      "        \"f1\": 0.2857142857142857\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"bart\": {\n",
      "    \"rouge\": {\n",
      "      \"rouge-1\": {\n",
      "        \"recall\": 53.846000000000004,\n",
      "        \"precision\": 28.571,\n",
      "        \"f1\": 37.333\n",
      "      },\n",
      "      \"rouge-2\": {\n",
      "        \"recall\": 32.0,\n",
      "        \"precision\": 16.667,\n",
      "        \"f1\": 21.918000000000003\n",
      "      },\n",
      "      \"rouge-3\": {\n",
      "        \"recall\": 25.0,\n",
      "        \"precision\": 12.766,\n",
      "        \"f1\": 16.901\n",
      "      },\n",
      "      \"rouge-4\": {\n",
      "        \"recall\": 21.739,\n",
      "        \"precision\": 10.870000000000001,\n",
      "        \"f1\": 14.493\n",
      "      },\n",
      "      \"rouge-l\": {\n",
      "        \"recall\": 50.0,\n",
      "        \"precision\": 26.531,\n",
      "        \"f1\": 34.666999999999994\n",
      "      },\n",
      "      \"rouge-su4\": {\n",
      "        \"recall\": 27.857,\n",
      "        \"precision\": 14.029,\n",
      "        \"f1\": 18.66\n",
      "      }\n",
      "    },\n",
      "    \"bleurt\": {\n",
      "      \"bleurt\": {\n",
      "        \"mean\": -0.8628984689712524,\n",
      "        \"max\": -0.8628984689712524\n",
      "      }\n",
      "    },\n",
      "    \"qaeval\": {\n",
      "      \"qa-eval\": {\n",
      "        \"f1\": 0.20634920634920634,\n",
      "        \"em\": 0.14285714285714285,\n",
      "        \"lerc\": 1.6535689319883073,\n",
      "        \"is_answered\": 0.42857142857142855\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"gsum\": {\n",
      "    \"rouge\": {\n",
      "      \"rouge-1\": {\n",
      "        \"recall\": 69.231,\n",
      "        \"precision\": 28.571,\n",
      "        \"f1\": 40.449\n",
      "      },\n",
      "      \"rouge-2\": {\n",
      "        \"recall\": 52.0,\n",
      "        \"precision\": 20.968,\n",
      "        \"f1\": 29.885\n",
      "      },\n",
      "      \"rouge-3\": {\n",
      "        \"recall\": 37.5,\n",
      "        \"precision\": 14.754000000000001,\n",
      "        \"f1\": 21.176000000000002\n",
      "      },\n",
      "      \"rouge-4\": {\n",
      "        \"recall\": 34.782999999999994,\n",
      "        \"precision\": 13.333,\n",
      "        \"f1\": 19.277\n",
      "      },\n",
      "      \"rouge-l\": {\n",
      "        \"recall\": 65.385,\n",
      "        \"precision\": 26.984,\n",
      "        \"f1\": 38.202000000000005\n",
      "      },\n",
      "      \"rouge-su4\": {\n",
      "        \"recall\": 45.714,\n",
      "        \"precision\": 17.68,\n",
      "        \"f1\": 25.497999999999998\n",
      "      }\n",
      "    },\n",
      "    \"bleurt\": {\n",
      "      \"bleurt\": {\n",
      "        \"mean\": -0.9817036986351013,\n",
      "        \"max\": -0.9817036986351013\n",
      "      }\n",
      "    },\n",
      "    \"qaeval\": {\n",
      "      \"qa-eval\": {\n",
      "        \"f1\": 0.2857142857142857,\n",
      "        \"lerc\": 1.7074798345565796,\n",
      "        \"em\": 0.2857142857142857,\n",
      "        \"is_answered\": 0.42857142857142855\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supported Papers\n",
    "There are currently 30+ papers with implementations in Repro, including models for text generation evaluation, question generation, question answering, summarization, and more\n",
    "\n",
    "Once Repro is installed, all of these papers' code can be run without any additional effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Links\n",
    "- Docker tutorial: https://github.com/danieldeutsch/repro/blob/master/tutorials/docker.md\n",
    "- Repro tutorial: https://github.com/danieldeutsch/repro/blob/master/tutorials/using-models.md\n",
    "- Contributing tutorial: https://github.com/danieldeutsch/repro/blob/master/tutorials/adding-a-model.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
