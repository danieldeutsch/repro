# Papers
This file contains a list of the papers with models wrapped by this library.

### Summarization
|Paper|Authors|Link|
|-|-|-|
|[BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://arxiv.org/abs/1910.13461)|Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer|[Link](models/lewis2020/Readme.md)|
|[Text Summarization with Pretrained Encoders](https://arxiv.org/abs/1908.08345)|Yang Liu and Mirella Lapata|[Link](models/liu2019/Readme.md)|
|[GSum: A General Framework for Guided Neural Abstractive Summarization](https://arxiv.org/abs/2010.08014)|Zi-Yi Dou, Pengfei Liu, Hiroaki Hayashi, Zhengbao Jiang, and Graham Neubig|[Link](models/dou2021/Readme.md)|

### Text Generation Evaluation
|Paper|Authors|Link|
|-|-|-|
|[ROUGE: A Package for Automatic Evaluation of Summaries](https://aclanthology.org/W04-1013/)|Chin-Yew Lin|[Link](models/sacrerouge/Readme.md)|
|[Towards Question-Answering as an Automatic Metric for Evaluating the Content Quality of a Summary](https://arxiv.org/abs/2010.00490)|Daniel Deutsch, Tania Bedrax-Weiss, and Dan Roth|[Link](models/deutsch2021/Readme.md)|
|[BLEURT: Learning Robust Metrics for Text Generation](https://arxiv.org/abs/2004.04696)|Thibault Sellam, Dipanjan Das, and Ankur P. Parikh|[Link](models/sellam2020/Readme.md)|
|[BERTScore: Evaluating Text Generation with BERT](https://arxiv.org/abs/1904.09675)|Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi|[Link](models/zhang2020/Readme.md)|
|[BLEU: A Method for Automatic Evaluation of Machine Translation](https://aclanthology.org/P02-1040/)|Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu|[Link](models/papineni2002/Readme.md)|
|[QuestEval: Summarization Asks for Fact-based Evaluation](https://arxiv.org/abs/2103.12693)|Thomas Scialom, Paul-Alexis Dray, Patrick Gallinari, Sylvain Lamprier, Benjamin Piwowarski, Jacopo Staiano, and Alex Wang|[Link](models/scialom2021/Readme.md)|

### Question Answering
|Paper|Authors|Link|
|-|-|-|
|[Neural Module Networks for Reasoning over Text](https://arxiv.org/abs/1912.04971)|Nitish Gupta, Kevin Lin, Dan Roth, Sameer Singh, and Matt Gardner|[Link](models/gupta2020/Readme.md)|
|[Towards Question-Answering as an Automatic Metric for Evaluating the Content Quality of a Summary](https://arxiv.org/abs/2010.00490)|Daniel Deutsch, Tania Bedrax-Weiss, and Dan Roth|[Link](models/deutsch2021/Readme.md)|

### Question Generation
|Paper|Authors|Link|
|-|-|-|
|[Towards Question-Answering as an Automatic Metric for Evaluating the Content Quality of a Summary](https://arxiv.org/abs/2010.00490)|Daniel Deutsch, Tania Bedrax-Weiss, and Dan Roth|[Link](models/deutsch2021/Readme.md)|

### Others
|Paper|Authors|Link|
|-|-|-|
|[RoFT: A Tool for Evaluating Human Detection of Machine-Generated Text](https://arxiv.org/abs/2010.03070)|Liam Dugan, Daphne Ippolito, Arun Kirubarajan, and Chris Callison-Burch|[Link](models/dugan2020/Readme.md)|
|[Learning to Capitalize with Character-Level Recurrent Neural Networks: An Empirical Study](https://aclanthology.org/D16-1225/)|Raymond Hendy Susanto, Hai Leong Chieu, and Wei Lu|[Link](models/susanto2016/Readme.md)|
|[MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics](https://arxiv.org/abs/2010.03636)|Anthony Chen, Gabriel Stanovsky, Sameer Singh, and Matt Gardner|[Link](models/chen2020/Readme.md)|

