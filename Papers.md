This file contains a list of the papers with models wrapped by this library.

|Paper|Authors|Link|
|-|-|-|
|[Neural Module Networks for Reasoning over Text](https://arxiv.org/abs/1912.04971)|Nitish Gupta, Kevin Lin, Dan Roth, Sameer Singh, and Matt Gardner|[Link](models/gupta2020/Readme.md)|
|[BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://arxiv.org/abs/1910.13461)|Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer|[Link](models/lewis2020/Readme.md)
|[Text Summarization with Pretrained Encoders](https://arxiv.org/abs/1908.08345)|Yang Liu and Mirella Lapata|[Link](models/liu2019/Readme.md)